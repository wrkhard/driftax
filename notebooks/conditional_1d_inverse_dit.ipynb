{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# driftax \u2014 Conditional inverse problem on a ring (bimodal posterior)\n",
        "\n",
        "We train a conditional generator **x ~ q\u03b8(x | y)** where:\n",
        "- **x** is a 2D point on a noisy ring\n",
        "- **y** is a 1D measurement: the x-coordinate (with heteroscedastic noise)\n",
        "\n",
        "Conditioning on y yields a **bimodal** posterior (upper/lower arc).\n",
        "\n",
        "This notebook:\n",
        "1) plots the training dataset (x, y)\n",
        "2) trains DiT1D (sequence length 2) with drifting loss\n",
        "3) visualizes conditional samples for a few y values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os, sys\n",
        "\n",
        "# Driftax notebook backend policy:\n",
        "# - macOS: FORCE CPU (avoid Metal instability)\n",
        "# - other OS: let JAX auto-select (GPU if available; else CPU)\n",
        "#\n",
        "# NOTE: must run BEFORE importing jax.\n",
        "for k in (\"JAX_PLATFORMS\", \"JAX_PLATFORM_NAME\"):\n",
        "    os.environ.pop(k, None)\n",
        "\n",
        "if sys.platform == \"darwin\":\n",
        "    os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import optax\n",
        "\n",
        "from driftax.datasets import inverse_ring_toy\n",
        "from driftax.dit1d import DiT1D, DiT1DConfig\n",
        "from driftax.conditioning import CondMLP\n",
        "from driftax.drift import drifting_loss_features\n",
        "\n",
        "print(\"JAX devices:\", jax.devices())\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Plot dataset snapshot\n",
        "key = jax.random.PRNGKey(0)\n",
        "x, y = inverse_ring_toy(key, 20000)\n",
        "x = np.array(x)\n",
        "y = np.array(y).squeeze(-1)\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.scatter(x[:,0], x[:,1], s=2, alpha=0.25)\n",
        "plt.axis(\"equal\")\n",
        "plt.title(\"Training dataset: noisy ring (x)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.scatter(y, x[:,1], s=2, alpha=0.15)\n",
        "plt.xlabel(\"y (measured x0)\")\n",
        "plt.ylabel(\"x1 (vertical)\")\n",
        "plt.title(\"Bimodal conditional structure: x1 | y\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Train DiT1D on ring conditional\n",
        "cfg = DiT1DConfig(length=2, patch=1, dim=256, depth=6, heads=4, cond_dim=256, drop=0.0)\n",
        "model = DiT1D(cfg)\n",
        "cond_net = CondMLP(in_dim=1, out_dim=cfg.cond_dim, hidden=256)\n",
        "\n",
        "batch = 512\n",
        "steps = 2000\n",
        "plot_every = 500\n",
        "temps = (0.02, 0.05, 0.2)\n",
        "lr = 2e-4\n",
        "\n",
        "key = jax.random.PRNGKey(1)\n",
        "key, k1, k2 = jax.random.split(key, 3)\n",
        "\n",
        "dummy_noise = jnp.zeros((1, 2), dtype=jnp.float32)\n",
        "dummy_y = jnp.zeros((1, 1), dtype=jnp.float32)\n",
        "\n",
        "cond_params = cond_net.init(k1, dummy_y)\n",
        "cond0 = cond_net.apply(cond_params, dummy_y)\n",
        "model_params = model.init(k2, dummy_noise, cond0, train=True)\n",
        "\n",
        "params = {\"cond\": cond_params, \"model\": model_params}\n",
        "opt = optax.adamw(lr)\n",
        "opt_state = opt.init(params)\n",
        "\n",
        "def loss_fn(params, key):\n",
        "    key, kdata, kz = jax.random.split(key, 3)\n",
        "    x_true, y = inverse_ring_toy(kdata, batch)\n",
        "    c = cond_net.apply(params[\"cond\"], y)\n",
        "    z = jax.random.normal(kz, (batch, 2), dtype=jnp.float32)\n",
        "    x_gen = model.apply(params[\"model\"], z, c, train=True)\n",
        "    return drifting_loss_features(\n",
        "        x_feat=x_gen,\n",
        "        pos_feat=x_true,\n",
        "        temps=temps,\n",
        "        neg_feat=x_gen,\n",
        "        feature_normalize=True,\n",
        "        drift_normalize=True,\n",
        "    )\n",
        "\n",
        "@jax.jit\n",
        "def step_fn(params, opt_state, key):\n",
        "    loss, grads = jax.value_and_grad(lambda p: loss_fn(p, key))(params)\n",
        "    updates, opt_state2 = opt.update(grads, opt_state, params)\n",
        "    params2 = optax.apply_updates(params, updates)\n",
        "    return params2, opt_state2, key, loss\n",
        "\n",
        "def conditional_plot(params, y0_list=(-0.6, 0.0, 0.6), n_gen=6000, tol=0.03):\n",
        "    # approximate true conditional by filtering a large sample set\n",
        "    k = jax.random.PRNGKey(123)\n",
        "    x_true, y_true = inverse_ring_toy(k, 80000)\n",
        "    xt = np.array(x_true)\n",
        "    yt = np.array(y_true).squeeze(-1)\n",
        "\n",
        "    fig, axes = plt.subplots(1, len(y0_list), figsize=(4*len(y0_list), 4), sharex=False, sharey=False)\n",
        "    if len(y0_list) == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for ax, y0 in zip(axes, y0_list):\n",
        "        mask = np.abs(yt - y0) < tol\n",
        "        ax.scatter(xt[mask,0], xt[mask,1], s=2, alpha=0.15, label=\"true ~p(x|y)\")\n",
        "\n",
        "        y_in = jnp.full((n_gen, 1), y0, dtype=jnp.float32)\n",
        "        c = cond_net.apply(params[\"cond\"], y_in)\n",
        "        kgen = jax.random.PRNGKey(int((y0 + 1.5) * 1000) % (2**31 - 1))\n",
        "        z = jax.random.normal(kgen, (n_gen, 2), dtype=jnp.float32)\n",
        "        xg = model.apply(params[\"model\"], z, c, train=False)\n",
        "        xg = np.array(xg)\n",
        "\n",
        "        ax.scatter(xg[:,0], xg[:,1], s=2, alpha=0.15, label=\"gen ~q(x|y)\")\n",
        "        ax.set_title(f\"y={y0:+.2f}\")\n",
        "        ax.set_aspect(\"equal\", adjustable=\"box\")\n",
        "        ax.set_xlim(-1.4, 1.4)\n",
        "        ax.set_ylim(-1.4, 1.4)\n",
        "\n",
        "    axes[0].legend(loc=\"lower left\", markerscale=3)\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "loss_hist = []\n",
        "for s in range(1, steps + 1):\n",
        "    params, opt_state, key, loss = step_fn(params, opt_state, key)\n",
        "    loss_hist.append(float(loss))\n",
        "\n",
        "    if s == 1 or (plot_every and s % plot_every == 0) or s == steps:\n",
        "        print(f\"step {s} loss {float(loss):.3e}\")\n",
        "        conditional_plot(params)\n",
        "\n",
        "loss_hist = np.asarray(loss_hist, dtype=np.float32)\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.plot(loss_hist, alpha=0.8)\n",
        "plt.yscale(\"log\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xlabel(\"Step\"); plt.ylabel(\"Loss\")\n",
        "plt.title(\"driftax ring conditional drifting loss\")\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}